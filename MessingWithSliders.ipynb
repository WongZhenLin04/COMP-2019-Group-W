{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75519f08-7e57-47d1-bb2f-9bbee3855894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 0.2.03 version. Select nrows to a small number when running on huge datasets.\n",
      "output = featurewiz(dataname, target, corr_limit=0.90, verbose=2, sep=',', \n",
      "\t\theader=0, test_data='',feature_engg='', category_encoders='',\n",
      "\t\tdask_xgboost_flag=False, nrows=None, skip_sulov=False)\n",
      "Create new features via 'feature_engg' flag : ['interactions','groupby','target']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import mne, glob\n",
    "from mne_features.feature_extraction import extract_features\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.fullDataExtraction import getRawArrayData\n",
    "from ipynb.fs.full.fullDataExtraction import extarctChannelNames\n",
    "from ipynb.fs.full.feature_selection import get_features\n",
    "import plotly.express as px\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import math\n",
    "from tensorflow import keras\n",
    "import dash_bootstrap_components as dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac5543e-e879-4675-b3ea-cd6bad8526f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEpochs(rawArrays):\n",
    "    sliced_epochs={}\n",
    "    for clip in rawArrays:\n",
    "        sliced_epochs[clip]= mne.make_fixed_length_epochs(rawArrays[clip], duration=1, preload=True,verbose=0)\n",
    "    return sliced_epochs\n",
    "\n",
    "def getRawArrays(matfile):\n",
    "    del matfile[\"__header__\"]\n",
    "    del matfile[\"__version__\"]\n",
    "    del matfile[\"__globals__\"]\n",
    "    clip_info={}\n",
    "    indexs=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    keyName=list(matfile.keys())[0][:-1]\n",
    "    channelNamesExtraction=extarctChannelNames(pd.read_excel(\"Preprocessed_EEG/channel-order.xlsx\"))\n",
    "    info=mne.create_info(channelNamesExtraction,200,'eeg')\n",
    "    for ind,i in enumerate(indexs):\n",
    "        rawData=matfile[keyName + str(i)]\n",
    "        clip_info[ind] = mne.io.RawArray(rawData,info,verbose=0)\n",
    "    return clip_info\n",
    "\n",
    "def makeValueMatrix(currentAnalysed):\n",
    "    result=pd.read_excel(\"Preprocessed_EEG/channel-order(topo).xlsx\").to_numpy().astype(np.float32)\n",
    "    #tracker value\n",
    "    k=0\n",
    "    for i in range(0,result.shape[0]):\n",
    "        for j in range (0,result.shape[1]):\n",
    "            if not(math.isnan(result[i][j])):\n",
    "                result[i][j]=currentAnalysed[k]\n",
    "                k+=1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def makePostionList(data):\n",
    "    position=[]\n",
    "    for column in range (0,500):\n",
    "        position.append(makeValueMatrix(data[:,column]))\n",
    "    return position\n",
    "\n",
    "def ExtractFeatures(sliced_epochs,features):\n",
    "    combined = np.zeros((1,len(features)*62))\n",
    "    for cut in sliced_epochs:\n",
    "        epoch_array=mne.Epochs.get_data(sliced_epochs[cut])\n",
    "        extracted_data=extract_features(epoch_array,200,features)\n",
    "        combined = np.vstack((combined,extracted_data))\n",
    "    combined = np.delete(combined, 0, axis=0)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f440186-e5fb-4612-bcfd-c7b76f5ce53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=pd.read_excel(\"Preprocessed_EEG/channel-order(viz).xlsx\")\n",
    "channelNames=channels.iloc[:,0]\n",
    "channelNames=np.ndarray.tolist(pd.Series.to_numpy(channelNames))\n",
    "channelNames.insert(0,\"Fp1\")\n",
    "ch_types = ['eeg'] * len(channelNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4fd36c-6396-4987-9fbb-b2d4f938f28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>63 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>60 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>200.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>100.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 8 non-empty values\n",
       " bads: []\n",
       " ch_names: Fp1, Fpz, Fp2, AF3, AF4, F7, F5, F3, F1, Fz, F2, F4, F6, F8, ...\n",
       " chs: 60 EEG\n",
       " custom_ref_applied: False\n",
       " dig: 63 items (3 Cardinal, 60 EEG)\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 100.0 Hz\n",
       " meas_date: unspecified\n",
       " nchan: 60\n",
       " projs: []\n",
       " sfreq: 200.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = mne.create_info(channelNames, ch_types=ch_types, sfreq=200)\n",
    "info.set_montage('standard_1020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae5cd5b7-52d0-4f2a-bb5f-21dd4fdfb326",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.delete(subject['djc_eeg1'], 61, 0)\n",
    "data=np.delete(data, 57, 0)\n",
    "evoked=mne.EvokedArray(data,info)\n",
    "transposedData=np.transpose(data)\n",
    "df = pd.DataFrame(transposedData, columns = channelNames)\n",
    "df = df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5109baf9-375c-4fb3-a044-ac62b900a0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################################\n",
      "############       F A S T   F E A T U R E  E N G G    A N D    S E L E C T I O N ! ########\n",
      "# Be judicious with featurewiz. Don't use it to create too many un-interpretable features! #\n",
      "############################################################################################\n",
      "Correlation Limit = 0.7\n",
      "Skipping feature engineering since no feature_engg input...\n",
      "Skipping category encoding since no category encoders specified in input...\n",
      "#### Single_Label Multi_Classification problem ####\n",
      "    Loaded train data. Shape = (210429, 13)\n",
      "#### Single_Label Multi_Classification problem ####\n",
      "No test data filename given...\n",
      "Classifying features using a random sample of 10000 rows from dataset...\n",
      "#### Single_Label Multi_Classification problem ####\n",
      "    loading a random sample of 10000 rows into pandas for EDA\n",
      "#######################################################################################\n",
      "######################## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
      "#######################################################################################\n",
      "        No variables were removed since no ID or low-information variables found in data set\n",
      "    target labels need to be converted...\n",
      "Completed label encoding of target variable = label\n",
      "How model predictions need to be transformed for label:\n",
      "\t{0: -1.0, 1: 0.0, 2: 1.0}\n",
      "#######################################################################################\n",
      "#####  Searching for Uncorrelated List Of Variables (SULOV) in 12 features ############\n",
      "#######################################################################################\n",
      "    there are no null values in dataset...\n",
      "    Removing (5) highly correlated variables:\n",
      "    ['hjorth_complexity', 'katz_fd', 'ptp_amp', 'std', 'variance']\n",
      "    Following (7) vars selected: ['diffEnt', 'hurst_exp', 'kurtosis', 'mean', 'skewness', 'hjorth_mobility', 'rms']\n",
      "Completed SULOV. 7 features selected\n",
      "Time taken for SULOV method = 7 seconds\n",
      "Finally 7 vars selected after SULOV\n",
      "Converting all features to numeric before sending to XGBoost...\n",
      "#######################################################################################\n",
      "#####    R E C U R S I V E   X G B O O S T : F E A T U R E   S E L E C T I O N  #######\n",
      "#######################################################################################\n",
      "Current number of predictors before recursive XGBoost = 7 \n",
      "Number of booster rounds = 20\n",
      "            selecting 3 features in this iteration\n",
      "            selecting 2 features in this iteration\n",
      "            selecting 1 features in this iteration\n",
      "    Completed XGBoost feature selection in 0 seconds\n",
      "#######################################################################################\n",
      "#####          F E A T U R E   S E L E C T I O N   C O M P L E T E D            #######\n",
      "#######################################################################################\n",
      "Selected 4 important features:\n",
      "['hjorth_mobility', 'diffEnt', 'rms', 'skewness']\n",
      "Total Time taken for featurewiz selection = 8 seconds\n",
      "Output contains a list of 4 important features and a train dataframe\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"emotionPredictionModel\")\n",
    "subject=loadmat('1_20131107.mat')\n",
    "rawArrays=getRawArrays(subject)\n",
    "slicedEpochs=makeEpochs(rawArrays)\n",
    "extractedData = ExtractFeatures(slicedEpochs,get_features())\n",
    "points=makePostionList(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a442e041-2255-4406-b684-b5df41abd7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 0s 584us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(extractedData)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "y_pred = y_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8404b1a0-bda1-4570-84a0-ce032b155d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "from dash import Dash, dcc, html, Input, Output\n",
    "from jupyter_dash import JupyterDash\n",
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.LUX])\n",
    "slider = html.Div(\n",
    "    [\n",
    "            dcc.Slider(\n",
    "            min=0,\n",
    "            max=500,\n",
    "            step=1,\n",
    "            value=7,\n",
    "            id=\"time\",\n",
    "            marks=None,\n",
    "            tooltip={\"always_visible\": True},\n",
    "            vertical=True\n",
    "        ),\n",
    "    ],\n",
    "    style = {\"height\":\"100%\",\"text-align\": \"center\",'padding-left':'50%', 'padding-right':'50%'}\n",
    ")\n",
    "app.layout=html.Div(children=[\n",
    "                dbc.Row([\n",
    "                    dbc.Col(slider,width=2),\n",
    "                    dbc.Col([\n",
    "                            dbc.Row([  \n",
    "                                    html.H1(id=\"emotion\")\n",
    "                                    ], justify=\"center\"),\n",
    "                            dbc.Row([\n",
    "                                    dbc.Col(dcc.Graph(id=\"lineChartFrontal\"),width=4),\n",
    "                                    dbc.Col(dcc.Graph(id=\"lineChartCentral\"),width=4),\n",
    "                                    dbc.Col(dcc.Graph(id=\"lineChartRightTemporal\"),width=4)\n",
    "                                    ]),\n",
    "                            dbc.Row([\n",
    "                                    dbc.Col(dcc.Graph(id=\"lineChartParietal\"),width=4),\n",
    "                                    dbc.Col(dcc.Graph(id=\"lineChartOccipital\"),width=4),\n",
    "                                    dbc.Col(dcc.Graph(id=\"lineChartLeftTemporal\"),width=4)\n",
    "                                    ]),\n",
    "                            dbc.Row([\n",
    "                                    dbc.Col(dcc.Graph(id=\"heatmap\"),width=4)\n",
    "                                    ]),\n",
    "                                \n",
    "                        ],width=10)\n",
    "                    ])\n",
    "                ])\n",
    "#function for updating heatmap when slider is moved\n",
    "@app.callback(Output(\"heatmap\", \"figure\"),\n",
    "              Input(\"time\", \"value\"))\n",
    "def updateHeatMap(time_instance):\n",
    "    heatMap = px.imshow(points[time_instance])\n",
    "    heatMap.update_xaxes(showticklabels=False)\n",
    "    heatMap.update_yaxes(showticklabels=False)\n",
    "    heatMap.update_layout(xaxis=dict(scaleanchor='y', constrain='domain'))\n",
    "    return heatMap\n",
    "#function for updating emotion prediction\n",
    "@app.callback(Output(\"emotion\", \"children\"),\n",
    "              Input(\"time\", \"value\"))\n",
    "def updatePrediction(time_instance):\n",
    "    if (y_pred[time_instance] == [1,0,0]):\n",
    "        emotion=\"positive\"\n",
    "    elif (y_pred[time_instance] == [0,1,0]):\n",
    "        emotion=\"nuetral\"\n",
    "    else:\n",
    "        emotion=\"negative\"  \n",
    "    emotionDiv=html.H1(emotion)\n",
    "    return emotionDiv\n",
    "#function for updating the line charts\n",
    "@app.callback(Output(\"lineChartFrontal\", \"figure\"),\n",
    "              Output(\"lineChartCentral\", \"figure\"),\n",
    "              Output(\"lineChartParietal\", \"figure\"),\n",
    "              Output(\"lineChartOccipital\", \"figure\"),\n",
    "              Output(\"lineChartLeftTemporal\", \"figure\"),\n",
    "              Output(\"lineChartRightTemporal\", \"figure\"),\n",
    "              Input(\"time\", \"value\"))\n",
    "def updateLineCharts(time_instance):\n",
    "    lineChartFrontal= px.line(df[['Fp1', 'Fpz', 'Fp2','AF3', 'AF4','F1', 'Fz', 'F2',]].head(time_instance))\n",
    "    lineChartCentral= px.line(df[['FC1', 'FCz', 'FC2','C3', 'C1', 'Cz', 'C2', 'C4']].head(time_instance))\n",
    "    lineChartParietal= px.line(df[['CP3', 'CP1', 'CPz', 'CP2', 'CP4','P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6']].head(time_instance))\n",
    "    lineChartOccipital= px.line(df[['PO7', 'PO5', 'PO3','POz', 'PO4', 'PO6', 'PO8','O1', 'Oz', 'O2']].head(time_instance))\n",
    "    lineChartLeftTemporal= px.line(df[['F4', 'F6', 'F8','FC4','FC6', 'FT8','C6','CP6', 'TP8','P8']].head(time_instance))\n",
    "    lineChartFrontal= px.line(df[['F7', 'F5', 'F3','FT7', 'FC5', 'FC3','C5','TP7', 'CP5','P7']].head(time_instance))\n",
    "    return lineChartFrontal,lineChartCentral,lineChartParietal,lineChartOccipital,lineChartLeftTemporal,lineChartFrontal\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "143d1bbc-ce7a-4ffd-85cc-0df6bbf8c9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fp1', 'Fpz', 'Fp2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2',\n",
       "       'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4',\n",
       "       'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8',\n",
       "       'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'P7',\n",
       "       'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3',\n",
       "       'POz', 'PO4', 'PO6', 'PO8', 'O1', 'Oz', 'O2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1918e7df-80fa-4f73-836f-54aed72681c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
